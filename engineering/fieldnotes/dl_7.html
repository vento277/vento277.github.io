<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" charset="UTF-8">
    <link href='https://fonts.googleapis.com/css?family=Inter' rel='stylesheet'>
    <title>Convolution II</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" type="image/x-icon" href="../../assets/favicon/favicon.ico">
    
    <!-- Include Mathlax CDN -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
            tex2jax: { inlineMath: [ ["$", "$"], ["\\(", "\\)"] ], displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
            TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
            messageStyle: "none"
        });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>

<body>
    <section class="header">
        <div class="title">
            Convolution II
        </div>
        <div class="author">
            Author: Peter Kim | Professor: Renjie Liao
        </div>
    </section>
    <hr><!------------------------------------------------------------------------------------------------------------------------------>

    <!--Start-->
    <p>
        This is a continuation from <a href = "dl_6.html">Convolution I</a>
    </p>

    <h1>2D Transposed Convolution</h1>
    <p>
        We know convolution can reduce the input size, e.g., with stride > 1. Can any convolution operator enlarge the input size? Yes, transposed convolution (strided convolution).
    </p>
    <figure class="image">
        <source srcset="https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/80.webp 80w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/160.webp 160w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/240.webp 240w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/320.webp 320w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/400.webp 400w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/480.webp 480w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/560.webp 560w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/640.webp 640w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/720.webp 720w,https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/777.webp 777w" sizes="(max-width: 777px) 100vw, 777px" type="image/webp">
        <img src="https://ckbox.cloud/c0b0d29181743234ae23/assets/xRlFR2DGmm_D/images/777.png" width="777" height="347">
    </figure>
    <figure class="image">
        <source srcset="https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/94.webp 94w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/188.webp 188w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/282.webp 282w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/376.webp 376w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/470.webp 470w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/564.webp 564w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/658.webp 658w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/752.webp 752w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/846.webp 846w,https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/939.webp 939w" sizes="(max-width: 939px) 100vw, 939px" type="image/webp"><img style="max-width:100%; height:auto;" src="https://ckbox.cloud/c0b0d29181743234ae23/assets/rrHnxqgqm7zh/images/939.png" width="939" height="412">
    </figure>
    <a class="caption">In practice, we do not pad zeros and then perform convolution due to computational cost.</a>
    <p>
        Convolution and its transposed version are mutually inverse only w.r.t. shapes of
        input and output, but not w.r.t. values of input and output. Also, convolution and deconvolution are mutually inverse w.r.t. values of input and output.
    </p>
    <p>
        The gradients of the following two convolutions have the same shape in im2patch (data-> toeplitz matrix) implementation.
        To distinguish them and output correct shapes in their transposed convolutions, we add output padding on one side in the 2nd case. 
        This is for transposed convolution. Whereas stride and padding is for vanilla convolution.        
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/N2B2LCLC/image.png">
    </figure>

    <h1>2D Dilated Convolution</h1>
    <p>
        We know the kernel size decides what elements are used in convolution at one location. Can we enlarge the kernel size without
        increasing the number of parameters?
        Yes, dilated (atrous) convolution.
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/Fqdrzyjw/image.png">
    </figure>
    <a class="caption">By using dilated kernels, we effectively increase the receptive field (the region of input that affects the output).</a>

    <h1>2D Grouped and Seperable Convolution </h1>
    <p>
        Can we maintain the same shaped input and output in convolution with fewer number of parameters?
        Yes, grouped convolution & separable convolution.
    </p>
    <p>
        Starting with the grouped, its concept was first introduced in AlexNet:
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/mrNSp6Fq/image.png">
    </figure>
    <p>
        Suppose we have a convolution layer applied to input (shape $H \times W \times c_1$). Then we switch to a grouped (# groups=2) convolution layer applied to the same input.
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/yCwS7W4/image.png">
    </figure>
    <p>
        Now, the seperable. Let us look at a 3x3 convolutional kernel:
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/k6zKy1zr/image.png">
    </figure>
    <a class="caption">Spatial separable kernels are rank one and
        can not represent full-rank kernels, thus
        being limited in terms of expressiveness
    </a>
    <p>
        In practice, one often use depthwise separable convolution:
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/GfTG04Cg/image.png">
    </figure>

    <h1>Pooling</h1>
    <p>
        A similar idea as convolution except that you replace weighted sum operator with some pooling operator (e.g., max, mean)
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/Wvpk0zms/image.png">
    </figure>
    <a class="caption">Pooling gives you permutation-invariance
    </a>
   
    <h1>Example Architectures</h1>
    <p>
        Let's lookat some examples:
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/N2JxrJW2/image.png">
    </figure>
    <a class="caption">Convolutional Neural Networks</a>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/K3W0TLS/image.png">
    </figure>
    <a class="caption">Translation/Shift Invariance</a>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/TBbLnym0/image.png">
    </figure>
    <a class="caption">Translation/Shift Equivariance Invariance</a>

    <h2>More on Invariance & Equivariance</h2>
    <p>
        What about other transformations, e.g., scaling, 2D/3D rotations?
        Vanilla CNNs do not have such properties. One can add data augmentation to make the model approximately have them.
        One can also design CNN architectures, e.g., spherical CNNs (rotation equivariant), that are guaranteed to have such properties.
    </p>
    <p>
        U-Net and ResNet is a popular fully-convolutional CNN architecture for pixel-level tasks like image segmentation.
    </p>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/274LPnmJ/image.png">
    </figure>
    <a class="caption">U-Net</a>
    <figure class="image">
        <source><img style="max-width:100%; height:auto;" src="https://i.ibb.co/RT28vVNx/image.png">
    </figure>
    <a class="caption">ResNet</a>
    
    <hr><!------------------------------------------------------------------------------------------------------------------------------>
    <section class="footer">
        <h3>Notes</h3>
        <p>
            [a]
        </p>
        <h3>References</h3>
        <p>
            [1]
        </p>
    </section>
</body>
</html>
