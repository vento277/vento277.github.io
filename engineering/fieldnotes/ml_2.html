<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" charset="UTF-8">
    <link href='https://fonts.googleapis.com/css?family=Inter' rel='stylesheet'>
    <title>Logistic Regression</title>
    <link rel="stylesheet" href="../../assets/style.css">
    <link rel="icon" type="image/x-icon" href="../../assets/favicon/favicon.ico">
    
    <!-- Include Mathlax CDN -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
            tex2jax: { inlineMath: [ ["$", "$"], ["\\(", "\\)"] ], displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
            TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
            messageStyle: "none"
        });
    </script>

    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>

<body>
    <section class="header">
        <div class="header-col-L2">Logistic Regression</div>
        <div class="header-col-R"></div>
    </section>

    <section>
        Logistic regression is a statistical model used for classification problems. Unlike linear regression, which predicts continuous values, logistic regression is used when the output is categorical.
        Some of the real world examples include spam detection (classifies emails as spam or not spam),
        image classification (identifies objects in an image) and disease diagnosis.
        <br><br>

        Logistic regression is often used beacuse it exactly outputs the probability of probability of y
        = true label conditioned on the input X. And the prediction changes significantly around 0, which helps distinguish
        boundary samples. Overall, it is more robust against outliers.
        <br><br>

        <h1>Classification Models</h1>
        Classification is the process of categorizing objects into predefined groups. The goal of a classification model is to learn from training data and generalize to unseen examples.
        Each sample in classification is represented as a feature vector of \(i\)-th training sample
        and \(n\)-th feature:
        \[
        x^{(i)} = (x_1^{(i)}, x_2^{(i)}, ..., x_n^{(i)})^T
        \]
    
        The corresponding categorical labels of a set of classes \( K \) is given as follows:
        \[
        y^{(i)} \in \{1, 2, \ldots, K\} \quad \forall i \in \{1, 2, \ldots, m\}
        \]
        <br>

        <h2>Classifiers</h2>
        In general, there are two types of classifiers. A binary classification which has
        two possible categories (1 or 0) and multi-class classifiers which has more than two possible categories
        (e.g., "cat", "dog", "horse").
        <br><br>

        Before diving deeper into the theory of classifiers, 
        it's important to understand how we define which data points belong to which category. 
        To do this, we introduce the concept of a decision boundaryâ€”a boundary that separates different 
        classes or categories.
        <br><br>

        In the case of linear classifiers, which is a type of linear model that classifies data based on a 
        linear combination of input features, this decision boundary is a straight line in 2D space. 
        This is because a linear classifier creates a linear decision surface, 
        and in 2D, this surface is a line. But the  
        decision boundary becomes a hyperplane in higher dimensions.
        <figure class="image" data-ckbox-resource-id="c9Wcy-jbUSGi">
            <picture>
                <source srcset="https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/131.webp 131w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/262.webp 262w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/393.webp 393w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/524.webp 524w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/655.webp 655w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/786.webp 786w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/917.webp 917w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/1048.webp 1048w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/1179.webp 1179w,https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/1301.webp 1301w" sizes="(max-width: 1301px) 100vw, 1301px" type="image/webp"><img src="https://ckbox.cloud/77402af5c9b103bf8297/assets/c9Wcy-jbUSGi/images/1301.png">
            </picture>
        </figure>
        <br>

        We also need to clarify the difference between likeligood and probability.
        In the context of probability, we assume the parameters are fixed and compute the likelihood of observing data under a given model or distribution. Essentially, probability refers to how likely a certain outcome is, given specific parameters.
        On the other hand, in the case of likelihood, we treat the data as fixed and vary the parameters of the model or distribution. The likelihood tells us how likely the parameters are, given the observed data.
        <br><br>

        In many machine learning contexts, our goal is to find the parameters that maximize the likelihood, a process known as maximum likelihood estimation (MLE). This allows us to select the model parameters that make the observed data most probable under the model.
        <br><br>

        <h2>Logit</h2>
        In machine learning, logit refers to the log-odds of a probability.
        It is used to map the linear combination of input features (such as weights and inputs) 
        to the probability of a class.
        Let's say that the odds of even A happening is given as $\frac{p}{1-p}$. Then the logit function
        is given as:
        \[
            \text{logit}(p) = \ln\left(\frac{p}{1-p}\right) \rightarrow \text{logit}^{-1}(z) = p = \frac{1}{1 + e^{-z}}
        \]

        Recall the function $f_{\Theta}(X) = X^T \Theta \in (-\infty, +\infty)$. Our goal here is to find
        $P(y = 1|X)$. So:
        \[
            P(\hat{y}=1|X) = \text{logit}^{-1}(X^T \Theta) = \frac{1}{1 + e^{-X^T \Theta}} \in (0,1)
        \]
        with the classiciation rule:
        \[
            \hat{y}=
            \begin{cases} 
            1 & \text{if } P(\hat{y}=1|X) \geq 0.5 \\
            0 & \text{otherwise}
            \end{cases}
        \]

        Since $\text{logit}^{-1}(X^T \Theta) \geq 0.5$ iff $X^T \Theta \geq 0$:
        \[
            \hat{y}=
            \begin{cases} 
            1 & \text{if } X^T \Theta \geq 0 \\
            0 & \text{otherwise}
            \end{cases}
        \]

        From this, we can observe that logistic regression is a generalized linear classifier. 
        And the decision boundary is the hyperplane $z = X^T \Theta$.
        <br><br>

        Note that sometimes $\text{logit}$ is denoted as $\text{sigmoid}$ or $\sigma$. 
        
        <br><br>
        <h1>Maximum Likelihood Estimation (MLE)</h1>
        How do we search for the optimal $\Theta$ through the training data to maximize the
        classification performance? Given i-th sample, we can write the general logit function as:
        \[
            P(\hat{y}^{(i)}=1|{X^{(i)}}) = \sigma^{-1}({X^{(i)}}^T \Theta) = \frac{1}{1 + e^{-{X^{(i)}}^T \Theta}} \in (0,1)
        \]
        with the supervision criteria:
        \[
            P(\hat{y}^{(i)}= j|{X^{(i)}}) = 
            \begin{cases} 
            j = 0 \rightarrow \text{approach} \; 0 & \text{if } y^{(i)} = 0 \\
            j = 1 \rightarrow \text{approach} \; 1 & \text{if } y^{(i)} = 1
            \end{cases}
        \]

        Using the criteria above, we can rewrite the logit function as:
        \[
            p_i := P(\hat{y}^{(i)}=1|{X^{(i)}})^{y^{(i)}} P(\hat{y}^{(i)}=0|{X^{(i)}})^{1-y^{(i)}}
        \]
        with:
        \[
            p_i =
            \begin{cases} 
            P(\hat{y}^{(i)}=0|{X^{(i)}}) & \text{if } y^{(i)} = 0 \\
            P(\hat{y}^{(i)}=1|{X^{(i)}}) & \text{if } y^{(i)} = 1
            \end{cases}
        \]

        <h2>Binary Cross-Entropy</h2>
        Now, if we consider the join probability of all samples, and try to maximize it:
        \[
            \max (p(\Theta)) = \max (\prod_{i=1}^{m} p_i) = - \min (\ln p(\Theta)) = - \sum_{i=1}^{m} \ln p_i
        \]
        \[
        = - \sum_{i=1}^{m} \left[y^{(i)} \ln (P(\hat{y}^{(i)} = 1| X^{(i)})) + (1 - y^{(i)}) \ln (1 - P(\hat{y}^{(i)} = 1 | X^{(i)})) \right]
        \]

        This result is a form of binary cross-entropy, which measures how well the model's predicted probabilities align with the actual labels.
        More generally, it takes the form:
        \[
            E_i(\Theta) = y^{(i)} ln (P(\hat{y}^{(i)} = 1| X^{(i)})) + (1 - y^{(i)}) \ln (1 - P(\hat{y}^{(i)} = 1 | X^{(i)}))
        \]

        And its error as:
        \[
            \text{Binary cross-entropy error} := -yln (P(y)) - (1-y)ln(1-P(y)), \; y \in \{0,1\}
        \]

        In our case, $P(y) =  P(\hat{y}^{(i)} = 1| X^{(i)}) = \frac{1}{1 + e^{-{X^{(i)}}^T \Theta}}$:
        \[
            error =
            \begin{cases} 
            - \ln (1 - \frac{1}{1 + e^{-{X^{(i)}}^T \Theta}}) & \text{if } y = 0 \\
            - \ln (\frac{1}{1 + e^{-{X^{(i)}}^T \Theta}}) & \text{if } y  = 1
            \end{cases}
        \]
        <figure class="image" data-ckbox-resource-id="IbZGanoKpZvI">
            <picture>
                <source srcset="https://ckbox.cloud/77402af5c9b103bf8297/assets/IbZGanoKpZvI/images/80.webp 80w,https://ckbox.cloud/77402af5c9b103bf8297/assets/IbZGanoKpZvI/images/160.webp 160w,https://ckbox.cloud/77402af5c9b103bf8297/assets/IbZGanoKpZvI/images/240.webp 240w,https://ckbox.cloud/77402af5c9b103bf8297/assets/IbZGanoKpZvI/images/320.webp 320w,https://ckbox.cloud/77402af5c9b103bf8297/assets/IbZGanoKpZvI/images/400.webp 400w,https://ckbox.cloud/77402af5c9b103bf8297/assets/IbZGanoKpZvI/images/480.webp 480w,https://ckbox.cloud/77402af5c9b103bf8297/assets/IbZGanoKpZvI/images/526.webp 526w" sizes="(max-width: 526px) 100vw, 526px" type="image/webp"><img src="https://ckbox.cloud/77402af5c9b103bf8297/assets/IbZGanoKpZvI/images/526.png">
            </picture>
        </figure>
        <br>

        <h2>Gradient descent</h2>
        Recall for <a href = "ml_1.html">Linear Regression</a>, we minimized RSS to find the optimal fit.
        We want to do the same for $E_i(\Theta)$. But finding the analytic solution to its derivatives is very difficult.
        So instead, we use gradient descent. It iteratively searches for the optimal solution instead of deriving
        to the solution directly. 
        <br><br>

        Plugging $P(y) =  P(\hat{y}^{(i)} = 1| X^{(i)}) = \frac{1}{1 + e^{-{X^{(i)}}^T \Theta}}$ into 
        $E_i(\Theta)$, we get:
        \[
            E(\Theta) = - \sum_{i=1}^{m} \left[y^{(i)} \ln (\frac{1}{1 + e^{-{X^{(i)}}^T \Theta}}) + (1 - y^{(i)}) \ln (1 - (\frac{1}{1 + e^{-{X^{(i)}}^T \Theta}})) \right]
        \]

        This reduces to the analytic solution:
        \[
            \nabla E(\Theta) = \frac{\partial E(\Theta)}{\partial \Theta} = \sum_{i=1}^{m} (\frac{1}{1 + e^{-{X^{(i)}}^T \Theta}} - y^{(i)}) X^{(i)}
        \]

        Putting this into the gradient descent algo box, we can derive at the optimal solution for $\Theta$:
        \[
            \boxed{
            \begin{array}{l}
            \textbf{Gradient Descent Algorithm:} \\
            \text{1. Initialize the parameters } \Theta \text{ (e.g., randomly).} \\
            \text{2. Set the learning rate } \alpha. \\
            \text{3. Repeat until convergence:} \\
            \quad \text{a. Compute the gradient of the cost function:} \\
            \quad \nabla E(\Theta) = \frac{\partial E(\Theta)}{\partial \Theta} = \sum_{i=1}^{m} \left( \frac{1}{1 + e^{-X^{(i)T} \Theta}} - y^{(i)} \right) X^{(i)} \\
            \quad \text{where } X^{(i)} \text{ represents the features and } y^{(i)} \text{ represents the labels.} \\
            \quad \text{b. Update the parameters:} \\
            \quad \Theta := \Theta - \alpha \nabla E(\Theta) \\
            \text{4. Continue until convergence or a maximum number of iterations.}
            \end{array}
            }
        \]
        <br>

        Let's try an example. If we apply a gradient descent to find the $\Theta^*$ that minimizes $f(\Theta) = \Theta^2$,
        with a step size $\alpha = 0.4$ given that $\Theta$ initializes to 10, and regard the algo converges 
        once $ |f(\Theta, t) - f(\Theta, t-1)| \leq 0.01 $, we first start by computing the derivatives:
        \[
            \frac{\partial f(\Theta)}{\partial \Theta} = 2 \Theta
        \]

        So the descent formulation is:
        \[
            \Theta_1 = \Theta_0 - \alpha 2 \Theta_0 = 10 - 2(0.4) \Theta = 10 - 8 = 2
        \]

        Going through with the iteration:
        \[
            \Theta_2 = 2 - 0.8(2) = 0.4 \quad \Theta_3 = 0.08 \quad \Theta_4 = 0.016
        \]

        Since $|0.016 - 0.08| \leq 0.01$, at least 4 iteration is required for it to converge. 
        <br><br>
                
        <hr>
        <i>
            <b>Notes</b><br>
            -
            <br><br>

            <b>References</b><br>  
            -
        </i>

        <br><br>
    </section>
</body>
</html>
